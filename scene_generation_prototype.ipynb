{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scene Generation Prototype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if you have CUDA enabled."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If not, remove \", device=0\" from the code cell.\n",
    "\n",
    "Also make sure to provide the correct path to your model that you're using."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline('text-generation', model=\"<ENTER MODEL PATH HERE>\", tokenizer=\"dbmdz/german-gpt2\", device=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check whether you can prompt the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN: Was sind nun wieder?MALE: Herr Baron!MALE: Du lest mir das Blatt, mein Junge! Zu dir, zu wem?MALE: O, fürwahr, dein Vater wollte\n"
     ]
    }
   ],
   "source": [
    "output = pipe(\"<s>\", return_full_text=False, max_new_tokens=50)[0][\"generated_text\"]\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------\n",
    "Run both code cells, then open the link"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Dramatic Networks\n",
    "import numpy as np\n",
    "\n",
    "def generate_choice(choices):\n",
    "  values_from_choices = list(choices.values())\n",
    "  keys_from_choices = list(choices.keys())\n",
    "  number = np.random.uniform()\n",
    "  for i in range(1, len(values_from_choices)+1):\n",
    "    if number < sum(values_from_choices[:i]):\n",
    "      return(keys_from_choices[i-1])\n",
    "\n",
    "def end_scene(end_prob):\n",
    "  number = np.random.uniform()\n",
    "  if number < end_prob:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def simulate_sequence(centrality, loyalty, scene_length_parameter):\n",
    "  sequence = []\n",
    "  end_prob = 0.01\n",
    "  current_char = generate_choice(centrality)\n",
    "  sequence.append(current_char)\n",
    "\n",
    "  for i in range(20):\n",
    "    next_char = generate_choice(loyalty[current_char])\n",
    "    if next_char == \"X\":\n",
    "      next_char = generate_choice(centrality)\n",
    "    current_char = next_char\n",
    "    sequence.append(current_char)\n",
    "\n",
    "    end_prob = end_prob * scene_length_parameter\n",
    "    if end_scene(end_prob):\n",
    "      break\n",
    "  return sequence\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "\n",
    "### Methods and variables\n",
    "centrality = {\n",
    "    \"A\": 0.8,\n",
    "    \"B\": 0.2,\n",
    "    \"C\": 0.2\n",
    "}\n",
    "\n",
    "loyalty = {\n",
    "    \"A\": {\n",
    "        \"B\": 0.1,\n",
    "        \"C\": 0.2,\n",
    "        \"X\": 0.7\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"A\": 0.8,\n",
    "        \"C\": 0.1,\n",
    "        \"X\": 0.1\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"A\": 0.8,\n",
    "        \"B\": 0.1,\n",
    "        \"X\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "display_history = []\n",
    "internal_history = []\n",
    "\n",
    "gender_dict = dict()\n",
    "character_dict = dict()\n",
    "\n",
    "character_sequence = []\n",
    "\n",
    "parameters = {\"top_p\": 1,\n",
    "              \"top_k\": 50,\n",
    "              \"temperature\": 1,\n",
    "              \"repetition_penalty\": 1,\n",
    "              \"context_length\": 3\n",
    "              }\n",
    "\n",
    "def dialogue_init(top_p, top_k, temperature, repetition_penalty, scene_length, context_length, nameA, nameB, nameC, genderA, genderB, genderC, textA, textB, textC, centr_A, centr_B, centr_C, loyalty_A_B, loyalty_A_C, loyalty_A_X, loyalty_B_A, loyalty_B_C, loyalty_B_X, loyalty_C_A, loyalty_C_B, loyalty_C_X):\n",
    "    # Initialize the dialogue with the character names and the initial dialogue lines for them\n",
    "    internal_history.clear()\n",
    "    display_history.clear()\n",
    "\n",
    "    centrality[\"A\"] = centr_A\n",
    "    centrality[\"B\"] = centr_B\n",
    "    centrality[\"C\"] = centr_C\n",
    "    loyalty[\"A\"][\"B\"] = loyalty_A_B\n",
    "    loyalty[\"A\"][\"C\"] = loyalty_A_C\n",
    "    loyalty[\"A\"][\"X\"] = loyalty_A_X\n",
    "    loyalty[\"B\"][\"A\"] = loyalty_B_A\n",
    "    loyalty[\"B\"][\"C\"] = loyalty_B_C\n",
    "    loyalty[\"B\"][\"X\"] = loyalty_B_X\n",
    "    loyalty[\"C\"][\"A\"] = loyalty_C_A\n",
    "    loyalty[\"C\"][\"B\"] = loyalty_C_B\n",
    "    loyalty[\"C\"][\"X\"] = loyalty_C_X\n",
    "\n",
    "    gender_dict[nameA] = genderA\n",
    "    gender_dict[nameB] = genderB\n",
    "    gender_dict[nameC] = genderC\n",
    "\n",
    "    character_dict[\"A\"] = nameA\n",
    "    character_dict[\"B\"] = nameB\n",
    "    character_dict[\"C\"] = nameC\n",
    "\n",
    "    if len(textA) > 0:\n",
    "        internal_history.append(f\"<s>{genderA}: {textA}\")\n",
    "        display_history.append(f\"{nameA}: {textA}\")\n",
    "    if len(textB) > 0:\n",
    "        internal_history.append(f\"<s>{genderB}: {textB}\")\n",
    "        display_history.append(f\"{nameB}: {textB}\")\n",
    "    if len(textC) > 0:\n",
    "        internal_history.append(f\"<s>{genderC}: {textC}\")\n",
    "        display_history.append(f\"{nameC}: {textC}\")\n",
    "\n",
    "    character_sequence.clear()\n",
    "    for c in simulate_sequence(centrality, loyalty, scene_length):\n",
    "        character_sequence.append(c)\n",
    "\n",
    "    parameters[\"context_length\"] = context_length\n",
    "    parameters[\"top_p\"] = top_p\n",
    "    parameters[\"top_k\"] = top_k\n",
    "    parameters[\"temperature\"] = temperature\n",
    "    parameters[\"repetition_penalty\"] = repetition_penalty\n",
    "\n",
    "    return \"Dialogue initialized with chosen settings\\n\\n\" + \"For debugging: \"+ \",\".join(character_sequence) + \"\\n\\n\" + show_dialogue()\n",
    "\n",
    "\n",
    "def show_dialogue():\n",
    "    # Display the history\n",
    "    return \"\\n\".join(display_history)\n",
    "\n",
    "\n",
    "def choose_next_character():\n",
    "    if len(character_sequence) > 0:\n",
    "        return character_sequence.pop(0)\n",
    "    else:\n",
    "        return \"END\"\n",
    "\n",
    "\n",
    "def generate_next_line():\n",
    "    new_character = choose_next_character()\n",
    "    if new_character == \"END\":\n",
    "        return show_dialogue() + \"\\n----End of scene----\"\n",
    "\n",
    "    new_character = character_dict[new_character]\n",
    "\n",
    "    cutoff_text = generate_line(\" \".join(internal_history[-parameters[\"context_length\"]:]) + \"<s>\" + gender_dict[new_character] + \":\")\n",
    "\n",
    "    display_history.append(f\"{new_character}: {cutoff_text}\")\n",
    "    internal_history.append(f\"<s>{gender_dict[new_character]}: {cutoff_text}\")\n",
    "    return show_dialogue()\n",
    "\n",
    "\n",
    "def cutoff_next_line(line):\n",
    "    pattern = r\".+?(?=(FEMALE|MALE|UNKNOWN))\"\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        first_dialog = match.group(0)\n",
    "        return first_dialog\n",
    "    else:\n",
    "        return \"---\"\n",
    "\n",
    "\n",
    "def generate_line(context):\n",
    "    new_text = pipe(context, return_full_text=False, max_new_tokens=50, do_sample=True, top_p=parameters[\"top_p\"], top_k=parameters[\"top_k\"],temperature=parameters[\"temperature\"], repetition_penalty=parameters[\"repetition_penalty\"])[0][\"generated_text\"]\n",
    "    cutoff_text = cutoff_next_line(new_text)\n",
    "    if cutoff_text != \"---\":\n",
    "        return cutoff_text\n",
    "    else:\n",
    "        return generate_line(context)\n",
    "\n",
    "\n",
    "def revise_last_line():\n",
    "    last_line_internal = internal_history.pop()\n",
    "    gender, line = last_line_internal.split(\"<s>\")[1].split(\": \", maxsplit=1)\n",
    "    last_line_display = display_history.pop()\n",
    "    name = last_line_display.split(\": \", maxsplit=1)[0]\n",
    "\n",
    "    cutoff_text = generate_line(\" \".join(internal_history[-parameters[\"context_length\"]:]) + \"<s>\" + gender + \":\")\n",
    "    display_history.append(f\"{name}: {cutoff_text}\")\n",
    "    internal_history.append(f\"<s>{gender}: {cutoff_text}\")\n",
    "    return show_dialogue()\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Theater Scene Generation Prototype\")\n",
    "    gr.Markdown(\"## Initialization\")\n",
    "    gr.Markdown(\"### Text generation parameters:\")\n",
    "    top_p = gr.Slider(minimum=0.5, maximum=1, value=1, step=0.01, interactive=True, label=\"top_p: How many tokens to consider (in terms of probability). | Lower values = Discard low-probability tokens, 1 = Consider all tokens for sampling\")\n",
    "    top_k = gr.Slider(minimum=1, maximum=100, value=50, step=1, interactive=True, label=\"top_k: How many tokens to consider (in terms of number of tokens). | Values must be between 1 and 100\")\n",
    "    temperature = gr.Slider(minimum=0, maximum=2, value=1, step=0.05, interactive=True, label=\"temperature: Modulates the token distribution. | Low = Greedy generation, High = Probability mass is more uniformly distributed\")\n",
    "    repetition_penalty = gr.Slider(minimum=1, maximum=1.5, value=1, step=0.01, interactive=True, info=\"Very experimental. Recommended value is 1. If text generation times out, it is likely caused by this parameter\",label=\"Repetition penalty | Low = No penalty, High = Avoid previously generated tokens\")\n",
    "\n",
    "\n",
    "    gr.Markdown(\"### Other parameters:\")\n",
    "    scene_length = gr.Slider(minimum=1.1, maximum=3, value=1.5, step=0.1, interactive=True, label=\"Scene length parameter: How long should the generated scene be by tendency? | 1 = longer; 3 = shorter\")\n",
    "    context_length = gr.Slider(minimum=1, maximum=10, value=3, step=1, interactive=True, label=\"Context length: How many of the last lines should be used as the prompt. | When using a CPU, 2-5 is recommended.\")\n",
    "\n",
    "\n",
    "    gr.Markdown(\"### Characters: \")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Character A:\")\n",
    "            nameA = gr.Textbox(label=\"Name of character A\")\n",
    "            genderA = gr.Dropdown([\"MALE\", \"FEMALE\", \"UNKNOWN\"], value=\"UNKNOWN\", label=\"Gender of character A\")\n",
    "            textA = gr.Textbox(label=\"First line of character A\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Character B:\")\n",
    "            nameB = gr.Textbox(label=\"Name of character B\")\n",
    "            genderB = gr.Dropdown([\"MALE\", \"FEMALE\", \"UNKNOWN\"], value=\"UNKNOWN\", label=\"Gender of character B\")\n",
    "            textB = gr.Textbox(label=\"First line of character B\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Character C:\")\n",
    "            nameC = gr.Textbox(label=\"Name of character C\")\n",
    "            genderC = gr.Dropdown([\"MALE\", \"FEMALE\", \"UNKNOWN\"], value=\"UNKNOWN\", label=\"Gender of character C\")\n",
    "            textC = gr.Textbox(label=\"First line of character C\")\n",
    "\n",
    "    gr.Examples(examples=[[\"Nathan\", \"MALE\", \"So macht nur, dass er euch hier nicht gewahr wird. Tretet mehr zurück. Geht lieber ganz hinein.\",\n",
    "                          \"Recha\", \"FEMALE\", \"Nur einen Blick noch! — Ah! die Hecke, die mir ihn stiehlt.\",\n",
    "                          \"Daja\", \"FEMALE\", \"Kommt! kommt! Der Vater hat ganz recht. Ihr lauft Gefahr, wenn er Euch sieht, dass auf der Stell’ er umkehrt.\"\n",
    "                          ]], inputs=[nameA, genderA, textA, nameB, genderB, textB, nameC, genderC, textC] )\n",
    "\n",
    "\n",
    "    gr.Markdown(\"### Character parameters:\")\n",
    "    gr.Markdown(\"**Important:**\\n Centrality values have to add up to 1. (e.g., A: 0.8, B: 0.2, C: 0.2)\\n Loyalty values for each character (within a column) have to add up to 1. (e.g., A->B: 0.1, A->C: 0.4, A->X: 0.5)\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Parameters for character A:\")\n",
    "            centr_A = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Centrality of A\", value=0.8)\n",
    "            loyalty_A_B = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of A to B\", value=0.1)\n",
    "            loyalty_A_C = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of A to C\", value=0.2)\n",
    "            loyalty_A_X = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Chance that A will end dialogue\", value=0.7)\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Parameters for character B:\")\n",
    "            centr_B = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Centrality of B\", value=0.2)\n",
    "            loyalty_B_A = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of B to A\", value=0.8)\n",
    "            loyalty_B_C = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of B to C\", value=0.1)\n",
    "            loyalty_B_X = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Chance that B will end dialogue\", value=0.1)\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Parameters for character C:\")\n",
    "            centr_C = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Centrality of C\", value=0.2)\n",
    "            loyalty_C_A = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of C to A\", value=0.8)\n",
    "            loyalty_C_B = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Loyalty of C to B\", value=0.1)\n",
    "            loyalty_C_X = gr.Slider(minimum=0, maximum=1, step=0.1, interactive=True, label=\"Chance that C will end dialogue\", value=0.1)\n",
    "\n",
    "    init_btn = gr.Button(\"Initialize play\")\n",
    "\n",
    "    gr.Markdown(\"## Generated scene\")\n",
    "    output = gr.Textbox(label=\"Scene\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            generate_btn = gr.Button(\"Generate next line\")\n",
    "        with gr.Column():\n",
    "            revise_btn = gr.Button(\"Revise last line\")\n",
    "\n",
    "\n",
    "    ### Functionalities\n",
    "\n",
    "    # Initialization\n",
    "    init_btn.click(fn=dialogue_init, inputs=[top_p, top_k, temperature, repetition_penalty, scene_length, context_length,nameA, nameB, nameC, genderA, genderB, genderC, textA, textB, textC, centr_A, centr_B, centr_C, loyalty_A_B, loyalty_A_C, loyalty_A_X, loyalty_B_A, loyalty_B_C, loyalty_B_X, loyalty_C_A, loyalty_C_B, loyalty_C_X], outputs=output)\n",
    "\n",
    "    # Generate next line\n",
    "    generate_btn.click(fn=generate_next_line, inputs=None, outputs=output)\n",
    "\n",
    "    # Revise last line\n",
    "    revise_btn.click(fn=revise_last_line, inputs=None, outputs=output)\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
